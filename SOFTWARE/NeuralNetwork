import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import pyfirmata
import time 
plt.style.use('dark_background')

from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten
import keras.utils
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split

from tensorflow.keras.layers import Flatten
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Activation,Dense, BatchNormalization,Dropout
from tensorflow.keras import optimizers
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns 
from tensorflow.keras.optimizers import SGD

from sklearn.linear_model import LogisticRegression
import pandas
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasClassifier
from keras.utils import np_utils
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline

# fix random seed for reproducibility
seed = 7
np.random.seed(seed)

### Normalize inputs
#WHat happens if we don't normalize inputs?
# ALso we may have to normalize depending on the activation function
tf.random.set_seed(13)
tf.debugging.set_log_device_placement(False)


Flat = np.array([[903,1194,928,1004,0,959],
                [923,1239,945,1018,923,977],
                [927,1172,955,1024,0,959],
                [928,1422,952,1022,0,956],
                [924,1214,945,1019,923,976]])
Flat = Flat - np.average(Flat)
cuLF = np.array([[729,3466,840,926,542,599],
                [715,3475,965,983,630,648],
                [701,3473,809,959,595,659],
                [732,21111,812,941,594,687],
                [736,3476,844,988,605,670]])
cuLF = cuLF - np.average(cuLF)
cuDF = np.array([[834,643,886,884,815,868],
                [906,688,883,902,808,889],
                [753,688,794,857,842,874],
                [749,688,819,884,867,872],
                [690,678,847,885,824,874]])
cuDF = cuDF - np.average(cuDF)
cuRF = np.array([[586,913,634,873,0,836],
                [621,992,686,914,0,880],
                [659,951,641,902,0,846],
                [572,3354,602,875,0,843],
                [593,3355,624,891,0,857]])
cuRF = cuRF - np.average(cuRF)
cuUF = np.array([[461,3376,470,699,0,924],
                [412,3456,452,636,407,686],
                [419,3372,456,561,0,662],
                [422,3380,456,585,0,687],
                [450,3384,438,520,0,617]])
cuUF = cuUF - np.average(cuUF)

labels = np.array([[0],
[0],
[0],
[0],
[0],
[1],
[1],
[1],
[1],
[1],
[2],
[2],
[2],
[2],
[2],
[3],
[3],
[3],
[3],
[3],
[4],
[4],
[4],
[4],
[4]])

feature_set = np.vstack([Flat,cuLF,cuDF,cuRF,cuUF])
dataSet = np.append(feature_set,labels,axis=1)
dataSet = pd.DataFrame(dataSet, columns = ['Sensor1','Sensor2','Sensor3','Sensor4','Sensor5','Sensor6','class'])
# print(feature_set)
# print(labels)
#print(dataSet)

all_ds = dataSet.sample(frac=1)
#print(all_ds)



train_dataset, temp_test_dataset = train_test_split(all_ds,test_size=0.5)
#print(train_dataset.shape)
#print(temp_test_dataset.shape) 

test_dataset, valid_dataset = train_test_split(temp_test_dataset,test_size = 0.5)
# some print statements can go here to show the split

train_stats = train_dataset.describe()
train_stats.pop("class")
sns.pairplot(train_stats[train_stats.columns], diag_kind="kde")

train_stats = train_dataset.describe()
train_stats.pop("class")
train_stats=train_stats.transpose()
#print(train_stats)

train_labels1 = train_dataset.pop('class')
test_labels1 = test_dataset.pop('class')
valid_labels1 = valid_dataset.pop('class')

train_labels = pd.get_dummies(train_labels1,prefix='class')
test_labels = pd.get_dummies(test_labels1,prefix='class')
valid_labels = pd.get_dummies(valid_labels1,prefix='class')
#print(train_labels)

def norm(x):
    return (x - train_stats['mean'])/train_stats['std']

normed_train_data = norm(train_dataset)
normed_test_data = norm(test_dataset)
normed_valid_data = norm(valid_dataset)

x_train = normed_train_data
x_test = normed_test_data

y_train = train_labels1
y_test = test_labels1

encoder = LabelEncoder()
encoder.fit(labels)
encoded_Y = encoder.transform(labels)
dummy_Y = np_utils.to_categorical(encoded_Y)

model = Sequential()
model.add(Dense(5, input_dim=6, kernel_initializer='normal', activation='relu'))
model.add(tf.keras.layers.Dense(32, activation='relu'))
model.add(Dense(5, kernel_initializer='normal', activation='sigmoid'))
# Compile model
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    
model.fit(x_train,y_train)
predictions = model.predict(x_test)
print(predictions)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations=[tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
tflite_model = converter.convert()

open('Echo_glove_dNN_Arduino'+'.tflite','wb').write(tflite_model)



# Function: Convert some hex value into an array for C programming
def hex_to_c_array(hex_data, var_name):

  c_str = ''

  # Create header guard
  c_str += '#ifndef ' + var_name.upper() + '_H\n'
  c_str += '#define ' + var_name.upper() + '_H\n\n'

  # Add array length at top of file
  c_str += '\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\n'

  # Declare C variable
  c_str += 'unsigned char ' + var_name + '[] = {'
  hex_array = []
  for i, val in enumerate(hex_data) :

    # Construct string from hex
    hex_str = format(val, '#04x')

    # Add formatting so each line stays within 80 characters
    if (i + 1) < len(hex_data):
      hex_str += ','
    if (i + 1) % 12 == 0:
      hex_str += '\n '
    hex_array.append(hex_str)

  # Add closing brace
  c_str += '\n ' + format(' '.join(hex_array)) + '\n};\n\n'

  # Close out header guard
  c_str += '#endif //' + var_name.upper() + '_H'

  return c_str

# Write TFLite model to a C source (or header) file
with open('Echo_glove_dNN_Arduino' + '.h', 'w') as file:
  file.write(hex_to_c_array(tflite_model, 'Echo_glove_dNN_Arduino'))




  board = pyfirmata.Arduino("COM9")
  while True:
      time.sleep(0.1)
      print()
    #   board.digitalWrite[12].write(1)
    #   board.digitalWrite[10].write(1)
    #   board.digitalWrite[8].write(1)
    #   board.digitalWrite[6].write(1)
    #   board.digitalWrite[29].write(1)
    #   board.digitalWrite[2].write(1)
       
    #   board.digitalWrite[13].write(0);
    #   board.digitalWrite[11].write(0);
    #   board.digitalWrite[9].write(0);
    #   board.digitalWrite[7].write(0);
    #   board.digitalWrite[31].write(0);
    #   board.digitalWrite[3].write(0);
      
#   digitalWrite(trigPinOne, LOW);
#   echoTimeOne = pulseIn(echoPinOne, HIGH);
#   digitalWrite(trigPinTwo, LOW);
#   echoTimeTwo = pulseIn(echoPinTwo, HIGH);
#   digitalWrite(trigPinThree, LOW);
#   echoTimeThree = pulseIn(echoPinThree, HIGH);
#   digitalWrite(trigPinFour, LOW);
#   echoTimeFour = pulseIn(echoPinFour, HIGH);
#   digitalWrite(trigPinFive, LOW);
#   echoTimeFive = pulseIn(echoPinFive, HIGH);
#   digitalWrite(trigPinSix, LOW);
#   echoTimeSix = pulseIn(echoPinSix, HIGH);

#   distanceOne = echoTimeOne;
#   distanceTwo = echoTimeTwo;
#   distanceThree = echoTimeThree;
#   distanceFour = echoTimeFour;
#   distanceFive = echoTimeFive;
#   distanceSix = echoTimeSix;
#   //  if (i == 1){
#   Serial.println(" ");
#   Serial.print(distanceOne);
#   Serial.print(",");
#   Serial.print(distanceSix);
#   Serial.print(",");
#   Serial.print(distanceThree);
#   Serial.print(",");
#   Serial.print(distanceFive);
#   Serial.print(",");
#   Serial.print(distanceTwo);
#   Serial.print(",");
#   Serial.print(distanceFour);
#   Serial.print(",");
#   //  }

#   if (distanceOne < 0.0) {
#     distanceOne = 0;
#   }


#   int  squeeze = (distanceOne / 20000) * 180;

#   servoOne.write(squeeze);
#   servoTwo.write(squeeze);
#   servoThree.write(squeeze);
#   servoFour.write(squeeze);

#   int prevprevsqueeze = prevsqueeze;
#   int prevsqueeze = squeeze;
  #)
